{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPGqFph0hWNA"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# # Run this to use from colab environment\n",
        "# !pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "e1614342-6bac-4c4b-d431-f01272b75dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n"
          ]
        }
      ],
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "#from adni.load_data import load_data\n",
        "#from brats.load_data import load_data\n",
        "from load_data import load_data\n",
        "#from ecg.load_data import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import seaborn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats import weightstats\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "features = data.drop(columns=['label'])\n",
        "label = data.label\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=.2)\n",
        "\n",
        "y_train_bin = []\n",
        "for val in y_train:\n",
        "  if val == 'T12':\n",
        "    y_train_bin.append(0)\n",
        "  else:\n",
        "    y_train_bin.append(1) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAa7WJCd56fk"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhortF6M6BJh"
      },
      "source": [
        "##Removing features with certain amount of zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3KCn2TrF6GgK"
      },
      "outputs": [],
      "source": [
        "# def dropper(train, test, N_ZEROS):\n",
        "#   X_train_drop = train.copy()\n",
        "#   X_test_drop = test.copy()\n",
        "#   X_dropped = []\n",
        "#   for column in train.columns:\n",
        "#     if list(train[column]).count(0) >N_ZEROS:\n",
        "#       X_train_drop.drop(columns=column, inplace=True)\n",
        "#       X_dropped.append(column)\n",
        "\n",
        "#   X_test_drop.drop(columns=X_dropped, inplace=True)\n",
        "#   print(f'Number of features before drop: {len(X_train.columns)}')\n",
        "#   print(f'Number of features after drop: {len(X_train_drop.columns)}')\n",
        "#   return X_train_drop, X_test_drop\n",
        "\n",
        "\n",
        "# X_train_drop, X_test_drop = dropper(X_train, X_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8qaMN_7Unb"
      },
      "source": [
        "##Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q6BJaMI37Vq7"
      },
      "outputs": [],
      "source": [
        "# Scale the dataset\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V55PGYOyPp0A"
      },
      "source": [
        "##Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQsEWuviPvxG"
      },
      "source": [
        "###Z-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PXDFa7mVPyd2",
        "outputId": "aca9c33a-f77f-4dab-b235-413a806be361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(159,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/86/5f0w_b1966108xb6wznvlrcm0000gn/T/ipykernel_3479/1022151370.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train['Grade'] = y_train_bin\n"
          ]
        }
      ],
      "source": [
        "# Test normal distribution\n",
        "# X_train_df = pd.DataFrame(X_train, columns = X_train.columns)\n",
        "X_train['Grade'] = y_train_bin\n",
        "X_T12 = X_train.groupby('Grade').get_group(0)\n",
        "X_T34 = X_train.groupby('Grade').get_group(1)\n",
        "X_T12 = X_T12.drop(columns = ['Grade'])\n",
        "X_T34 = X_T34.drop(columns = ['Grade'])\n",
        "\n",
        "# ztest,pval = weightstats.ztest(X_T12,X_T34)\n",
        "_,pval = stats.ttest_ind(X_T12,X_T34)\n",
        "\n",
        "\n",
        "print(pval.shape)\n",
        "feat_sig = []\n",
        "for id, val in enumerate(pval):\n",
        "  if val < 0.05/len(X_train):\n",
        "    feat_sig.append(list(X_train.columns)[id])\n",
        "\n",
        "X_feat_sig_train = X_train[feat_sig]\n",
        "X_feat_sig_train.columns =['Feature'+ str(pc) for pc in range(1,len(feat_sig)+1)]\n",
        "# X_feat_sig_train['Grade'] = y_train_bin\n",
        "#print(len(feat_sig))\n",
        "# seaborn.pairplot(X_feat_sig_train, hue = 'Grade')\n",
        "\n",
        "X_feat_sig_test = X_test[feat_sig]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AyeFbkovFxiN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# scaler = RobustScaler()\n",
        "# scaler.fit(X_feat_sig_train)\n",
        "# X_train_scaled = scaler.transform(X_feat_sig_train)\n",
        "# X_test_scaled = scaler.transform(X_feat_sig_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emhz-AV_yGv"
      },
      "source": [
        "##PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qR_LfjKs-V9s"
      },
      "outputs": [],
      "source": [
        "N_COMP = 10\n",
        "pca = PCA(n_components=N_COMP)\n",
        "pca.fit(X_feat_sig_train)\n",
        "X_train_pca = pca.transform(X_feat_sig_train)\n",
        "X_test_pca = pca.transform(X_feat_sig_test)\n",
        "y_train_bin = []\n",
        "\n",
        "\n",
        "# seaborn.scatterplot(x=X_train_pca[:,0],y=X_train_pca[:,1],hue=y_train)\n",
        "# scatter_data = pd.DataFrame(X_train_pca[:,:], columns = ['Principal component' + str(pc) for pc in range(1,N_COMP+1)])\n",
        "# scatter_data['Stage'] = y_train_bin\n",
        "# seaborn.pairplot(scatter_data, hue = 'Stage')\n",
        "# print(scatter_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQWNGavlBlF0"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ztLj3EAJyU",
        "outputId": "ca47719e-ce58-4b90-d5dd-61fb8abcf6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training result kNN: 0.7666666666666667\n",
            "Test result kNN: 0.8260869565217391\n",
            "Training result Random Forest: 0.9555555555555556\n",
            "Test result Random Forest: 0.7391304347826086\n"
          ]
        }
      ],
      "source": [
        "# kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train_pca, y_train)\n",
        "score_train_kNN = knn.score(X_train_pca, y_train)\n",
        "score_test_kNN = knn.score(X_test_pca, y_test)\n",
        "print(f\"Training result kNN: {score_train_kNN}\")\n",
        "print(f\"Test result kNN: {score_test_kNN}\")\n",
        "\n",
        "\n",
        "# RF with PCA\n",
        "# clf = RandomForestClassifier(n_estimators=5, bootstrap=True)\n",
        "# clf.fit(X_train_pca, y_train)\n",
        "# score_train_RF = clf.score(X_train_pca, y_train)\n",
        "# score_test_RF = clf.score(X_test_pca, y_test)\n",
        "# print(f\"Training result Random Forest: {score_train_RF}\")\n",
        "# print(f\"Test result Random Forest: {score_test_RF}\")\n",
        "\n",
        "\n",
        "# RF without PCA\n",
        "clf = RandomForestClassifier(n_estimators=5, bootstrap=True)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "score_train_RF = clf.score(X_train_scaled, y_train)\n",
        "score_test_RF = clf.score(X_test_scaled, y_test)\n",
        "print(f\"Training result Random Forest: {score_train_RF}\")\n",
        "print(f\"Test result Random Forest: {score_test_RF}\")\n",
        "\n",
        "# Print result\n",
        "\n",
        "# print(f\"Test result: {score_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnfuoX7LB8D7"
      },
      "outputs": [],
      "source": [
        "-"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "H&N group 12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
