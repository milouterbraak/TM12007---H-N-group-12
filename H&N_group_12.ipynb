{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPGqFph0hWNA"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# # Run this to use from colab environment\n",
        "# !pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "e1614342-6bac-4c4b-d431-f01272b75dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n"
          ]
        }
      ],
      "source": [
        "from load_data import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2, SequentialFeatureSelector\n",
        "import seaborn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats import weightstats\n",
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "# Classifiers and kernels\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "features = data.drop(columns=['label'])\n",
        "label = data.label\n",
        "\n",
        "\n",
        "# Splitting data in train and test group\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=.2)\n",
        "\n",
        "# functie van maken??\n",
        "y_train_bin = []\n",
        "for val in y_train:\n",
        "  if val == 'T12':\n",
        "    y_train_bin.append(0)\n",
        "  else:\n",
        "    y_train_bin.append(1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAa7WJCd56fk"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Removing outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bramschalkwijk/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        }
      ],
      "source": [
        "# Create the dataframe\n",
        "outlier_feat = []\n",
        "for feature in X_train.columns:\n",
        "    # IQR\n",
        "    Q1 = np.percentile(X_train[feature], 25,\n",
        "                    interpolation = 'midpoint')\n",
        "    \n",
        "    Q3 = np.percentile(X_train[feature], 75,\n",
        "                    interpolation = 'midpoint')\n",
        "    IQR = Q3 - Q1\n",
        " \n",
        "    if not IQR == 0:\n",
        "        # Upper bound\n",
        "        X_train.loc[X_train[feature] > (Q3+1.5*IQR),feature] = Q3\n",
        "        # Lower bound\n",
        "        X_train.loc[X_train[feature] < (Q1-1.5*IQR),feature] = Q1\n",
        "\n",
        "\n",
        "for feature in X_test.columns:\n",
        "    \n",
        "    # IQR\n",
        "    Q1 = np.percentile(X_test[feature], 25,\n",
        "                    interpolation = 'midpoint')\n",
        "    \n",
        "    Q3 = np.percentile(X_test[feature], 75,\n",
        "                    interpolation = 'midpoint')\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    if not IQR == 0:\n",
        "        # Upper bound\n",
        "        X_test.loc[X_test[feature] > (Q3+1.5*IQR),feature] = Q3\n",
        "        # Lower bound\n",
        "        X_test.loc[X_test[feature] < (Q1-1.5*IQR),feature] = Q1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8qaMN_7Unb"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 487,
      "metadata": {
        "id": "q6BJaMI37Vq7"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns = features.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns = features.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V55PGYOyPp0A"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQsEWuviPvxG"
      },
      "source": [
        "### T-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PXDFa7mVPyd2",
        "outputId": "aca9c33a-f77f-4dab-b235-413a806be361"
      },
      "outputs": [],
      "source": [
        "# X_train_scaled_df = pd.DataFrame(X_train_scaled, columns = X_train.columns) # make df from numpy\n",
        "# X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_train.columns)\n",
        "# X_train_scaled_df['Label'] = y_train_bin\n",
        "# X_train_T12 = X_train_scaled_df.groupby('Label').get_group(0)\n",
        "# X_train_T34 = X_train_scaled_df.groupby('Label').get_group(1)\n",
        "# X_train_T12 = X_train_T12.drop(columns = ['Label'])\n",
        "# X_train_T34 = X_train_T34.drop(columns = ['Label'])\n",
        "\n",
        "# # ttest\n",
        "# _,pval = stats.ttest_ind(X_train_T12,X_train_T34)\n",
        "\n",
        "\n",
        "\n",
        "# sig_feat = []\n",
        "# for id, val in enumerate(pval):\n",
        "#   if val < 0.05/X_train_scaled_df.shape[1]:\n",
        "#     sig_feat.append(list(X_train.columns)[id])\n",
        "# print(f'Number of significant different features: {len(sig_feat)}')\n",
        "\n",
        "# X_train_sig = X_train_scaled_df[sig_feat]\n",
        "# X_test_sig = X_test_scaled_df[sig_feat]\n",
        "\n",
        "# # # Pairplot of sign features\n",
        "# # X_train_sig.columns =['Feature'+ str(pc) for pc in range(1,len(sig_feat)+1)]\n",
        "# # X_train_sig['Grade'] = y_train_bin\n",
        "# # pair_plot = seaborn.pairplot(X_train_sig, hue = 'Grade')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Greedy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cfs = RandomForestClassifier(n_estimators=5, bootstrap=True)\n",
        "\n",
        "\n",
        "# t_it = np.zeros(159)\n",
        "# for it in range(20):\n",
        "#     print(it)\n",
        "#     cfs = KNeighborsClassifier(n_neighbors=5)\n",
        "#     sfs = SequentialFeatureSelector(cfs,n_features_to_select=5)\n",
        "#     X_train_fs = sfs.fit_transform(X_train_scaled, y_train)\n",
        "#     it = sfs.get_support()\n",
        "#     t_it = np.vstack([t_it,it])\n",
        "\n",
        "\n",
        "# voting = np.sum(t_it, axis=0)\n",
        "\n",
        "# THRES = 10\n",
        "# sig_feat = []\n",
        "# for id, value in enumerate(voting):\n",
        "#     if value > THRES:\n",
        "#         sig_feat.append(list(X_train.columns)[id])\n",
        "\n",
        "# X_train_scaled_df = pd.DataFrame(X_train_scaled, columns = X_train.columns) # make df from numpy\n",
        "# X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_train.columns)\n",
        "# X_train_sig = X_train_scaled_df[sig_feat]\n",
        "# X_test_sig = X_test_scaled_df[sig_feat]\n",
        "\n",
        "# X_train_sig\n",
        "# # X_test_fs = sfs.transform(X_test_scaled)\n",
        "\n",
        "cfs = KNeighborsClassifier(n_neighbors=5)\n",
        "sfs = SequentialFeatureSelector(cfs,n_features_to_select=60)\n",
        "X_train_fs = sfs.fit_transform(X_train_scaled, y_train)\n",
        "X_test_fs = sfs.transform(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emhz-AV_yGv"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {
        "id": "qR_LfjKs-V9s"
      },
      "outputs": [],
      "source": [
        "# N_COMP = 10\n",
        "# pca = PCA(n_components=N_COMP)\n",
        "# pca.fit(X_train_sig)\n",
        "# X_train_pca = pca.transform(X_train_sig)\n",
        "# X_test_pca = pca.transform(X_test_sig)\n",
        "\n",
        "\n",
        "# seaborn.scatterplot(x=X_train_pca[:,0],y=X_train_pca[:,1],hue=y_train)\n",
        "# scatter_data = pd.DataFrame(X_train_pca[:,:], columns = ['Principal component' + str(pc) for pc in range(1,N_COMP+1)])\n",
        "# scatter_data['Stage'] = y_train_bin\n",
        "# seaborn.pairplot(scatter_data, hue = 'Stage')\n",
        "# print(scatter_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQWNGavlBlF0"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ztLj3EAJyU",
        "outputId": "ca47719e-ce58-4b90-d5dd-61fb8abcf6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(n_neighbors=10)\n",
            "Train data acc: 0.8555555555555555\n",
            "Test data acc: 0.5217391304347826\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train_sig = X_train_fs\n",
        "X_test_sig = X_test_fs\n",
        "\n",
        "# Construct classifiers\n",
        "svmlin = SVC(kernel='linear', gamma='scale')\n",
        "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
        "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
        "\n",
        "# clsfs = [KNeighborsClassifier(), RandomForestClassifier(),QuadraticDiscriminantAnalysis(),GaussianNB(),LinearDiscriminantAnalysis(),svmlin, svmpoly, svmrbf]\n",
        "clsfs = [KNeighborsClassifier(n_neighbors=10)]\n",
        "\n",
        "for clf in clsfs:\n",
        "    # Fit classifier\n",
        "    clf.fit(X_train_sig,y_train)\n",
        "    y_pred_train=clf.predict(X_train_sig)\n",
        "    print(clf)\n",
        "    acc_train = (y_train==y_pred_train).sum()/len(X_train_sig)\n",
        "    print(f'Train data acc: {acc_train}')\n",
        "    y_pred_test = clf.predict(X_test_sig)\n",
        "    acc_test = (y_test==y_pred_test).sum()/len(X_test_sig)\n",
        "    print(f'Test data acc: {acc_test}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best classifier: k=7\n",
            "Best classifier: k=11\n",
            "Best classifier: k=5\n",
            "Best classifier: k=7\n",
            "Best classifier: k=7\n",
            "The optimal N=7\n",
            "THe AUC on the replication set is 0.6785714285714286 using a 7-NN classifier\n",
            "Training result kNN: 0.8444444444444444\n",
            "Test result kNN: 0.6086956521739131\n"
          ]
        }
      ],
      "source": [
        "## Optimization\n",
        "### KNN\n",
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "results = []\n",
        "best_n_neighbors = []\n",
        "X_train_sig_a = X_train_sig\n",
        "y_train_a = y_train.to_numpy()\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_sig_a,y_train_a):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_sig_a[validation_index]\n",
        "    y_validation = y_train_a[validation_index]\n",
        "    \n",
        "    X_test_op = X_train_sig_a[test_index]\n",
        "    y_test_op = y_train_a[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_neighbors\": list(range(1, 31, 2))}\n",
        "    knn = KNeighborsClassifier()\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "    grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_neighbors}')\n",
        "    best_n_neighbors.append(clf.n_neighbors)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_test_op)\n",
        "    scores = probabilities[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_test_op, scores)\n",
        "    results.append({\n",
        "        'auc': auc,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'test'\n",
        "    })\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "# seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "# print(results)\n",
        "\n",
        "\n",
        "# Use the optimal parameters without any tuning to validate the optimal classifier\n",
        "clf = KNeighborsClassifier(n_neighbors=optimal_n)\n",
        "\n",
        "# Fit on the entire dataset\n",
        "clf.fit(X_train_sig, y_train)\n",
        "\n",
        "# Test the classifier on the indepedent replication data\n",
        "probabilities = clf.predict_proba(X_test_sig)\n",
        "scores = probabilities[:, 1]\n",
        "\n",
        "# Get the auc\n",
        "auc = metrics.roc_auc_score(y_test, scores)\n",
        "print(f'THe AUC on the replication set is {auc} using a {clf.n_neighbors}-NN classifier')\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=optimal_n)\n",
        "knn.fit(X_train_sig, y_train)\n",
        "score_train_kNN = knn.score(X_train_sig, y_train)\n",
        "score_test_kNN = knn.score(X_test_sig, y_test)\n",
        "print(f\"Training result kNN: {score_train_kNN}\")\n",
        "print(f\"Test result kNN: {score_test_kNN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "id": "TnfuoX7LB8D7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best classifier: n=10\n",
            "Best classifier: n=11\n",
            "Best classifier: n=20\n",
            "Best classifier: n=30\n",
            "Best classifier: n=8\n",
            "The optimal N=11\n",
            "        auc   n         set\n",
            "0  0.962500  10        test\n",
            "1  0.945216  10  validation\n",
            "2  0.839506  11        test\n",
            "3  0.941699  11  validation\n",
            "4  0.901235  20        test\n",
            "5  0.956757  20  validation\n",
            "6  0.790123  30        test\n",
            "7  0.966795  30  validation\n",
            "8  0.796296   8        test\n",
            "9  0.948263   8  validation\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "results = []\n",
        "best_n_neighbors = []\n",
        "X_train_sig_a = X_train_sig\n",
        "y_train_a = y_train.to_numpy()\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_sig_a,y_train_a):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_sig_a[validation_index]\n",
        "    y_validation = y_train_a[validation_index]\n",
        "    \n",
        "    X_test = X_train_sig_a[test_index]\n",
        "    y_test = y_train_a[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_estimators\": list(range(1, 50))}\n",
        "    rf = RandomForestClassifier(criterion= \"gini\", bootstrap = True, min_samples_leaf = 5)\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "    grid_search = model_selection.GridSearchCV(rf, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: n={clf.n_estimators}')\n",
        "    best_n_neighbors.append(clf.n_estimators)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_test)\n",
        "    scores = probabilities[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_test, scores)\n",
        "    results.append({\n",
        "        'auc': auc,\n",
        "        'n': clf.n_estimators,\n",
        "        'set': 'test'\n",
        "    })\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'n': clf.n_estimators,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "print(results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "H&N group 12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
