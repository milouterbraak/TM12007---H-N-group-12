{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPGqFph0hWNA"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# # Run this to use from colab environment\n",
        "# !pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "e1614342-6bac-4c4b-d431-f01272b75dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n"
          ]
        }
      ],
      "source": [
        "from load_data import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import seaborn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats import weightstats\n",
        "\n",
        "# Classifiers and kernels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "features = data.drop(columns=['label'])\n",
        "label = data.label\n",
        "\n",
        "# Splitting data in train and test group\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=.2)\n",
        "\n",
        "# functie van maken??\n",
        "y_train_bin = []\n",
        "for val in y_train:\n",
        "  if val == 'T12':\n",
        "    y_train_bin.append(0)\n",
        "  else:\n",
        "    y_train_bin.append(1) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAa7WJCd56fk"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8qaMN_7Unb"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "q6BJaMI37Vq7"
      },
      "outputs": [],
      "source": [
        "# Scale the dataset\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V55PGYOyPp0A"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQsEWuviPvxG"
      },
      "source": [
        "### T-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PXDFa7mVPyd2",
        "outputId": "aca9c33a-f77f-4dab-b235-413a806be361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of significant different features: 25\n"
          ]
        }
      ],
      "source": [
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns = X_train.columns) # make df from numpy\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_train.columns)\n",
        "X_train_scaled_df['Label'] = y_train_bin\n",
        "X_train_T12 = X_train_scaled_df.groupby('Label').get_group(0)\n",
        "X_train_T34 = X_train_scaled_df.groupby('Label').get_group(1)\n",
        "X_train_T12 = X_train_T12.drop(columns = ['Label'])\n",
        "X_train_T34 = X_train_T34.drop(columns = ['Label'])\n",
        "\n",
        "# ttest\n",
        "_,pval = stats.ttest_ind(X_train_T12,X_train_T34)\n",
        "\n",
        "\n",
        "\n",
        "sig_feat = []\n",
        "for id, val in enumerate(pval):\n",
        "  if val < 0.05/X_train_scaled_df.shape[1]:\n",
        "    sig_feat.append(list(X_train.columns)[id])\n",
        "print(f'Number of significant different features: {len(sig_feat)}')\n",
        "\n",
        "X_train_sig = X_train_scaled_df[sig_feat]\n",
        "X_test_sig = X_test_scaled_df[sig_feat]\n",
        "\n",
        "# # Pairplot of sign features\n",
        "# X_train_sig.columns =['Feature'+ str(pc) for pc in range(1,len(sig_feat)+1)]\n",
        "# X_train_sig['Grade'] = y_train_bin\n",
        "# pair_plot = seaborn.pairplot(X_train_sig, hue = 'Grade')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emhz-AV_yGv"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "qR_LfjKs-V9s"
      },
      "outputs": [],
      "source": [
        "N_COMP = 10\n",
        "pca = PCA(n_components=N_COMP)\n",
        "pca.fit(X_train_sig)\n",
        "X_train_pca = pca.transform(X_train_sig)\n",
        "X_test_pca = pca.transform(X_test_sig)\n",
        "\n",
        "\n",
        "# seaborn.scatterplot(x=X_train_pca[:,0],y=X_train_pca[:,1],hue=y_train)\n",
        "# scatter_data = pd.DataFrame(X_train_pca[:,:], columns = ['Principal component' + str(pc) for pc in range(1,N_COMP+1)])\n",
        "# scatter_data['Stage'] = y_train_bin\n",
        "# seaborn.pairplot(scatter_data, hue = 'Stage')\n",
        "# print(scatter_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQWNGavlBlF0"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ztLj3EAJyU",
        "outputId": "ca47719e-ce58-4b90-d5dd-61fb8abcf6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier()\n",
            "Train data acc: 0.7888888888888889\n",
            "Test data acc: 0.7391304347826086\n",
            "RandomForestClassifier()\n",
            "Train data acc: 1.0\n",
            "Test data acc: 0.6521739130434783\n",
            "QuadraticDiscriminantAnalysis()\n",
            "Train data acc: 0.9222222222222223\n",
            "Test data acc: 0.6086956521739131\n",
            "GaussianNB()\n",
            "Train data acc: 0.7555555555555555\n",
            "Test data acc: 0.6521739130434783\n",
            "LinearDiscriminantAnalysis()\n",
            "Train data acc: 0.8555555555555555\n",
            "Test data acc: 0.5217391304347826\n",
            "SVC(kernel='linear')\n",
            "Train data acc: 0.8222222222222222\n",
            "Test data acc: 0.6956521739130435\n",
            "SVC(kernel='poly')\n",
            "Train data acc: 0.7444444444444445\n",
            "Test data acc: 0.6956521739130435\n",
            "SVC()\n",
            "Train data acc: 0.8222222222222222\n",
            "Test data acc: 0.6956521739130435\n"
          ]
        }
      ],
      "source": [
        "# Construct classifiers\n",
        "svmlin = SVC(kernel='linear', gamma='scale')\n",
        "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
        "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
        "\n",
        "clsfs = [KNeighborsClassifier(), RandomForestClassifier(),QuadraticDiscriminantAnalysis(),GaussianNB(),LinearDiscriminantAnalysis(),svmlin, svmpoly, svmrbf]\n",
        "\n",
        "for clf in clsfs:\n",
        "    # Fit classifier\n",
        "    clf.fit(X_train_sig,y_train)\n",
        "    y_pred_train=clf.predict(X_train_sig)\n",
        "    print(clf)\n",
        "    acc_train = (y_train==y_pred_train).sum()/len(X_train_sig)\n",
        "    print(f'Train data acc: {acc_train}')\n",
        "    y_pred_test = clf.predict(X_test_sig)\n",
        "    acc_test = (y_test==y_pred_test).sum()/len(X_test_sig)\n",
        "    print(f'Test data acc: {acc_test}')\n",
        "\n",
        "# clsfs = [KNeighborsClassifier(n_neighbors=5, weights='distance'),KNeighborsClassifier(n_neighbors=5),KNeighborsClassifier(n_neighbors=5),KNeighborsClassifier(n_neighbors=10)]\n",
        "\n",
        "# for clf in clsfs:\n",
        "#     # Fit classifier\n",
        "#     clf.fit(X_train_sig,y_train)\n",
        "#     y_pred_train=clf.predict(X_train_sig)\n",
        "#     print(clf)\n",
        "#     acc_train = (y_train==y_pred_train).sum()/len(X_train_sig)\n",
        "#     print(f'Train data acc: {acc_train}')\n",
        "#     y_pred_test = clf.predict(X_test_sig)\n",
        "#     acc_test = (y_test==y_pred_test).sum()/len(X_test_sig)\n",
        "#     print(f'Test data acc: {acc_test}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "TnfuoX7LB8D7"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (476313318.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Input \u001b[1;32mIn [61]\u001b[1;36m\u001b[0m\n\u001b[1;33m    -\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "-"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "H&N group 12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
