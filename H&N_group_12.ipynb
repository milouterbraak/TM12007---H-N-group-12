{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPGqFph0hWNA"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# # Run this to use from colab environment\n",
        "# !pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "e1614342-6bac-4c4b-d431-f01272b75dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n"
          ]
        }
      ],
      "source": [
        "from load_data import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import seaborn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats import weightstats\n",
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "# Classifiers and kernels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "features = data.drop(columns=['label'])\n",
        "label = data.label\n",
        "\n",
        "# Splitting data in train and test group\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=.2)\n",
        "#print(features)\n",
        "\n",
        "y_train_bin = []\n",
        "for val in y_train:\n",
        "  if val == 'T12':\n",
        "    y_train_bin.append(0)\n",
        "  else:\n",
        "    y_train_bin.append(1) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAa7WJCd56fk"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8qaMN_7Unb"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "q6BJaMI37Vq7"
      },
      "outputs": [],
      "source": [
        "# Scale the dataset\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns = features.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns = features.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Removing outliers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the dataframe\n",
        "outlier_feat = []\n",
        "for feature in X_train_scaled.columns:\n",
        "    # IQR\n",
        "    Q1 = np.percentile(X_train_scaled[feature], 25,\n",
        "                    interpolation = 'midpoint')\n",
        "    \n",
        "    Q3 = np.percentile(X_train_scaled[feature], 75,\n",
        "                    interpolation = 'midpoint')\n",
        "    IQR = Q3 - Q1\n",
        " \n",
        "    # Upper bound\n",
        "    X_train_scaled.loc[X_train_scaled[feature] >= (Q3+1.5*IQR),feature] = statistics.median(X_train_scaled[feature])\n",
        "\n",
        "    # Lower bound\n",
        "    X_train_scaled.loc[X_train_scaled[feature] <= (Q3-1.5*IQR),feature] = statistics.median(X_train_scaled[feature])\n",
        "\n",
        "\n",
        "for feature in X_test_scaled.columns:\n",
        "    # IQR\n",
        "    Q1 = np.percentile(X_test_scaled[feature], 25,\n",
        "                    interpolation = 'midpoint')\n",
        "    \n",
        "    Q3 = np.percentile(X_test_scaled[feature], 75,\n",
        "                    interpolation = 'midpoint')\n",
        "    IQR = Q3 - Q1\n",
        " \n",
        "    # Upper bound\n",
        "    X_test_scaled.loc[X_test_scaled[feature] >= (Q3+1.5*IQR),feature] = statistics.median(X_test_scaled[feature])\n",
        "    # Lower bound\n",
        "    X_test_scaled.loc[X_test_scaled[feature] <= (Q3-1.5*IQR),feature] = statistics.median(X_test_scaled[feature])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V55PGYOyPp0A"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQsEWuviPvxG"
      },
      "source": [
        "### T-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PXDFa7mVPyd2",
        "outputId": "aca9c33a-f77f-4dab-b235-413a806be361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of significant different features: 19\n"
          ]
        }
      ],
      "source": [
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns = X_train.columns) # make df from numpy\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_train.columns)\n",
        "X_train_scaled_df['Label'] = y_train_bin\n",
        "X_train_T12 = X_train_scaled_df.groupby('Label').get_group(0)\n",
        "X_train_T34 = X_train_scaled_df.groupby('Label').get_group(1)\n",
        "X_train_T12 = X_train_T12.drop(columns = ['Label'])\n",
        "X_train_T34 = X_train_T34.drop(columns = ['Label'])\n",
        "\n",
        "# ttest\n",
        "_,pval = stats.ttest_ind(X_train_T12,X_train_T34)\n",
        "\n",
        "\n",
        "sig_feat = []\n",
        "for id, val in enumerate(pval):\n",
        "  if val < 0.05/X_train_scaled_df.shape[1]:\n",
        "    sig_feat.append(list(X_train.columns)[id])\n",
        "print(f'Number of significant different features: {len(sig_feat)}')\n",
        "\n",
        "X_train_sig = X_train_scaled_df[sig_feat]\n",
        "X_test_sig = X_test_scaled_df[sig_feat]\n",
        "# #Pairplot of sign features\n",
        "# X_train_sig.columns =['Feature'+ str(pc) for pc in range(1,len(sig_feat)+1)]\n",
        "# X_train_sig['Label'] = y_train_bin\n",
        "# pair_plot = seaborn.pairplot(X_train_sig, hue = 'Label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emhz-AV_yGv"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "qR_LfjKs-V9s"
      },
      "outputs": [],
      "source": [
        "# N_COMP = 10\n",
        "# pca = PCA(n_components=N_COMP)\n",
        "# pca.fit(X_train_sig)\n",
        "# X_train_pca = pca.transform(X_train_sig)\n",
        "# X_test_pca = pca.transform(X_test_sig)\n",
        "\n",
        "\n",
        "# seaborn.scatterplot(x=X_train_pca[:,0],y=X_train_pca[:,1],hue=y_train)\n",
        "# scatter_data = pd.DataFrame(X_train_pca[:,:], columns = ['Principal component' + str(pc) for pc in range(1,N_COMP+1)])\n",
        "# scatter_data['Stage'] = y_train_bin\n",
        "# seaborn.pairplot(scatter_data, hue = 'Stage')\n",
        "# print(scatter_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQWNGavlBlF0"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing variety of classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ztLj3EAJyU",
        "outputId": "ca47719e-ce58-4b90-d5dd-61fb8abcf6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier()\n",
            "Train data acc: 0.8111111111111111\n",
            "Test data acc: 0.6086956521739131\n",
            "RandomForestClassifier()\n",
            "Train data acc: 1.0\n",
            "Test data acc: 0.6521739130434783\n",
            "QuadraticDiscriminantAnalysis()\n",
            "Train data acc: 0.8222222222222222\n",
            "Test data acc: 0.7391304347826086\n",
            "GaussianNB()\n",
            "Train data acc: 0.7444444444444445\n",
            "Test data acc: 0.8260869565217391\n",
            "LinearDiscriminantAnalysis()\n",
            "Train data acc: 0.7666666666666667\n",
            "Test data acc: 0.5652173913043478\n",
            "SVC(kernel='linear')\n",
            "Train data acc: 0.7777777777777778\n",
            "Test data acc: 0.6086956521739131\n",
            "SVC(kernel='poly')\n",
            "Train data acc: 0.7666666666666667\n",
            "Test data acc: 0.6521739130434783\n",
            "SVC()\n",
            "Train data acc: 0.8222222222222222\n",
            "Test data acc: 0.6521739130434783\n"
          ]
        }
      ],
      "source": [
        "# Construct classifiers\n",
        "svmlin = SVC(kernel='linear', gamma='scale')\n",
        "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
        "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
        "\n",
        "clsfs = [KNeighborsClassifier(), RandomForestClassifier(),QuadraticDiscriminantAnalysis(),GaussianNB(),LinearDiscriminantAnalysis(),svmlin, svmpoly, svmrbf]\n",
        "\n",
        "for clf in clsfs:\n",
        "    # Fit classifier\n",
        "    clf.fit(X_train_sig,y_train)\n",
        "    y_pred_train=clf.predict(X_train_sig)\n",
        "    print(clf)\n",
        "    acc_train = (y_train==y_pred_train).sum()/len(X_train_sig)\n",
        "    print(f'Train data acc: {acc_train}')\n",
        "    y_pred_test = clf.predict(X_test_sig)\n",
        "    acc_test = (y_test==y_pred_test).sum()/len(X_test_sig)\n",
        "    print(f'Test data acc: {acc_test}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "id": "TnfuoX7LB8D7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=27\n",
            "Best classifier: k=5\n",
            "Best classifier: k=13\n",
            "The optimal N=25\n",
            "THe AUC on the replication set is 0.8412698412698412 using a 25-NN classifier\n",
            "Training result kNN: 0.6777777777777778\n",
            "Test result kNN: 0.6956521739130435\n"
          ]
        }
      ],
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "results = []\n",
        "best_n_neighbors = []\n",
        "X_train_sig_a = X_train_sig.to_numpy()\n",
        "y_train_a = y_train.to_numpy()\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_sig_a,y_train_a):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_sig_a[validation_index]\n",
        "    y_validation = y_train_a[validation_index]\n",
        "    \n",
        "    X_test_op = X_train_sig_a[test_index]\n",
        "    y_test_op = y_train_a[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_neighbors\": list(range(1, 31, 2))}\n",
        "    knn = KNeighborsClassifier()\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "    grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_neighbors}')\n",
        "    best_n_neighbors.append(clf.n_neighbors)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_test_op)\n",
        "    scores = probabilities[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_test_op, scores)\n",
        "    results.append({\n",
        "        'auc': auc,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'test'\n",
        "    })\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "# seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "# print(results)\n",
        "\n",
        "\n",
        "# Use the optimal parameters without any tuning to validate the optimal classifier\n",
        "clf = KNeighborsClassifier(n_neighbors=optimal_n)\n",
        "\n",
        "# Fit on the entire dataset\n",
        "clf.fit(X_train_sig, y_train)\n",
        "\n",
        "# Test the classifier on the indepedent replication data\n",
        "probabilities = clf.predict_proba(X_test_sig)\n",
        "scores = probabilities[:, 1]\n",
        "\n",
        "# Get the auc\n",
        "auc = metrics.roc_auc_score(y_test, scores)\n",
        "print(f'THe AUC on the replication set is {auc} using a {clf.n_neighbors}-NN classifier')\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=optimal_n)\n",
        "knn.fit(X_train_sig, y_train)\n",
        "score_train_kNN = knn.score(X_train_sig, y_train)\n",
        "score_test_kNN = knn.score(X_test_sig, y_test)\n",
        "print(f\"Training result kNN: {score_train_kNN}\")\n",
        "print(f\"Test result kNN: {score_test_kNN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23,)\n",
            "(23, 14)\n"
          ]
        }
      ],
      "source": [
        "print(y_test.shape)\n",
        "print(X_test_sig.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best classifier: n=12\n",
            "Best classifier: n=4\n",
            "Best classifier: n=10\n",
            "Best classifier: n=11\n",
            "Best classifier: n=25\n",
            "The optimal N=11\n",
            "        auc   n         set\n",
            "0  0.675000  12        test\n",
            "1  0.966049  12  validation\n",
            "2  0.635802   4        test\n",
            "3  0.918147   4  validation\n",
            "4  0.839506  10        test\n",
            "5  0.969112  10  validation\n",
            "6  0.753086  11        test\n",
            "7  0.942857  11  validation\n",
            "8  0.567901  25        test\n",
            "9  0.953668  25  validation\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXBElEQVR4nO3df5BdZ33f8feHdQzybxjLzrCykekqGEOxCxs51IXgUBvBlHGdMMUmGSYmVOMUK6KZ0Lj80SZhhpBx2qkqDEJhHE8mMW4mQUGkwj/CAE4ZGLSyZUvyD7ojjC2J4jWm4F9gZH/7xz0ql7tnrSt5j+5K+37N3Ln3nOd5zv2u5o4+95xzz3NSVUiSNOhFoy5AkrQwGRCSpFYGhCSplQEhSWplQEiSWh036gLm0+mnn17Lly8fdRmSdNTYtm3bo1W1tK3tmAqI5cuXMzU1NeoyJOmokeTbc7V5iEmS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtjqnrICR1Z/369UxPT4+6DPbu3QvA+Pj4SOuYmJhgzZo1I62hawaEpKPK008/PeoSFg0DQjoKLJRv7/qp6elp1q5dO+oyOt2TMSCko8D09DT/e9ddnH3Ss6MuZeSO/0nv1OmPv+20Og89Mdbp9g0I6Shx9knP8uHX/3DUZWgB+eidp3S6fX/FJElqZUBIklp1GhBJViV5IMl0kmtb2l+aZFOSe5J8I8lr+9oeTLIjyfYkHmyUpCOss3MQScaA64FLgD3A1iSbq+revm4fBrZX1eVJzm36v7Wv/eKqerSrGqWjxd69e3ny8bHOjznr6PLtx8c4sbkupAtd7kGsBKarandVPQPcDFw20Oc84IsAVXU/sDzJmR3WJEkaUpe/YhoHHu5b3gNcONDnbuBXgf+VZCXwCmAZ8F2ggNuSFPCpqtrYYa3SgjY+Ps6P93/HXzHpZ3z0zlN4cYdXlHcZEGlZVwPLHwPWJdkO7ADuAvY3bRdV1b4kZwC3J7m/qu6Y9SbJamA1wNlnnz1ftUvSotflIaY9wFl9y8uAff0dquqHVXVVVV0AvBdYCnyradvXPD8CbKJ3yGqWqtpYVZNVNbl0aet9tyVJh6HLPYitwIok5wB7gSuA9/R3SHIa8FRzjuL9wB1V9cMkJwIvqqrHm9eXAn/UYa3SgvfQE56kBvjuU73vtWee8NyIKxm9h54YY0WH2+8sIKpqf5JrgFuBMeCGqtqV5OqmfQPwauAvkjwL3Av8VjP8TGBTkgM13lRVt3RVq7TQTUxMjLqEBeOZZk6qF7/Cf5MVdPvZSNXgaYGj1+TkZE1NecmEdCw7MEHeunXrRlzJsSHJtqqabGvzSmpJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSqy7nYpJ0DFm/fj3TzTQXo3SghgNXVI/KxMQEa9asGWkNXTMgJB1VlixZMuoSFg0DQtJQjvVvy5rNcxCSpFYGhCSplQEhSWplQEiSWnUaEElWJXkgyXSSa1vaX5pkU5J7knwjyWuHHStJ6lZnAZFkDLgeeDtwHnBlkvMGun0Y2F5VrwPeC6w7hLGSpA51uQexEpiuqt1V9QxwM3DZQJ/zgC8CVNX9wPIkZw45VpLUoS4DYhx4uG95T7Ou393ArwIkWQm8Alg25FiacauTTCWZmpmZmafSJUldBkRa1tXA8seAlybZDqwB7gL2Dzm2t7JqY1VNVtXk0qVLX0C5kqR+XV5JvQc4q295GbCvv0NV/RC4CiBJgG81jxMONlaS1K0u9yC2AiuSnJPkeOAKYHN/hySnNW0A7wfuaELjoGMlSd3qbA+iqvYnuQa4FRgDbqiqXUmubto3AK8G/iLJs8C9wG8939iuapUkzZaq1kP7R6XJycmampoadRmSdNRIsq2qJtvavJJaktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUqtOAyLJqiQPJJlOcm1L+6lJPp/k7iS7klzV1/Zgkh1JtifxLkCSdIR1dsvRJGPA9cAlwB5ga5LNVXVvX7cPAPdW1TuTLAUeSPJXVfVM035xVT3aVY2SpLl1uQexEpiuqt3Nf/g3A5cN9Cng5CQBTgIeA/Z3WJMkaUhdBsQ48HDf8p5mXb+PA68G9gE7gLVV9VzTVsBtSbYlWT3XmyRZnWQqydTMzMz8VS9Ji1yXAZGWdTWw/DZgO/By4ALg40lOadouqqrXA28HPpDkzW1vUlUbq2qyqiaXLl06L4VLkroNiD3AWX3Ly+jtKfS7Cvhs9UwD3wLOBaiqfc3zI8AmeoesJElHSJcBsRVYkeScJMcDVwCbB/o8BLwVIMmZwKuA3UlOTHJys/5E4FJgZ4e1SpIGdPYrpqran+Qa4FZgDLihqnYlubpp3wB8BLgxyQ56h6R+v6oeTfJKYFPv3DXHATdV1S1d1bqQrF+/nunp6ZHWsHfvXgDGxwdPGR15ExMTrFmzZtRlSItSZwEBUFVbgC0D6zb0vd5Hb+9gcNxu4Pwua9Pcnn766VGXIGkB6DQgdOgWwrfltWvXArBu3boRVyJplJxqQ5LUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLXqNCCSrEryQJLpJNe2tJ+a5PNJ7k6yK8lVw46VJHWrs4BIMgZcD7wdOA+4Msl5A90+ANxbVecDbwH+S5LjhxwrSepQl3sQK4HpqtpdVc8ANwOXDfQp4OT07i16EvAYsH/IsZKkDnUZEOPAw33Le5p1/T4OvBrYB+wA1lbVc0OOlSR1qMuASMu6Glh+G7AdeDlwAfDxJKcMObb3JsnqJFNJpmZmZg6/WknSz+gyIPYAZ/UtL6O3p9DvKuCz1TMNfAs4d8ixAFTVxqqarKrJpUuXzlvxkrTYdRkQW4EVSc5JcjxwBbB5oM9DwFsBkpwJvArYPeRYSVKHjutqw1W1P8k1wK3AGHBDVe1KcnXTvgH4CHBjkh30Div9flU9CtA2tqtaJUmzdRYQAFW1BdgysG5D3+t9wKXDjpUkHTleSS1JamVASJJaGRCSpFYGhCSp1VABkeSXkpzct3xykgu7K0uSNGrD7kF8Eniib/nJZp0k6Rg1bECkqv7/VBfNfEmd/kRWkjRawwbE7iS/k+Tnmsdaelc8S5KOUcMGxNXAPwf20psn6UJgdVdFSZJGb6jDRFX1CL35kCRJi8RQAZHkz2mZbruq3jfvFUmSFoRhTzT/fd/rlwCXM8f025KkY8Owh5j+tn85yWeAf+ikIknSgnC4V1KvAM6ez0IkSQvLsOcgHuen5yAK+C7wH7oqSpI0esMeYjo5ycvo7Tm85MDqzqqSJI3csHsQ7wfW0rs39Hbgl4CvAb9ykHGrgHX07gr36ar62ED7h4Bf76vl1cDSqnosyYPA48CzwP6qmhzuT5IkzYf0zaAxd6feLUF/Efh6VV2Q5FzgD6vq3c8zZgz4JnAJvYvrtgJXVtW9c/R/J/Dvq+pXmuUHgckDtyAdxuTkZE1NTQ3b/WesX7+e6enpwxp7rDnw7zAxMTHiShaGiYkJ1qxZM+oypE4k2TbXF/Bhf+b6o6r6URKSvLiq7k/yqoOMWQlMV9XupoibgcuA1oAArgQ+M2Q98256eprtO+/j2RNeNqoSFowXPdP70rBt93dHXMnojT312KhLkEZm2IDYk+Q04O+A25N8n4NfBzEOPNy/DXpTdMyS5ARgFXBN3+oCbktSwKeqauMcY1fTTPtx9tkv7IdVz57wMp4+9x0vaBs6tiy539uia/Ea9iT15c3LP0jyJeBU4JaDDEvbpubo+07gq1XV/3Xtoqral+QMeqF0f1Xd0VLbRmAj9A4xHaQmSdKQDnnK7qr6ypBd9wBn9S0vY+69jisYOLxUVfua50eSbKJ3yGpWQEiSutHlLUe3AiuSnJPkeHohsHmwU5JTgV8GPte37sQDd7BLciJwKbCzw1olSQM6u+lPVe1Pcg1wK72fud5QVbuSXN20b2i6Xg7cVlVP9g0/E9iU5ECNN1XVwQ5pSZLmUad3hauqLcCWgXUbBpZvBG4cWLcbOL/L2iRJz6/LQ0ySpKOYASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFadBkSSVUkeSDKd5NqW9g8l2d48diZ5NsnLhhkrSepWZwGRZAy4Hng7cB5wZZLz+vtU1XVVdUFVXQD8R+ArVfXYMGMlSd3qcg9iJTBdVbur6hngZuCy5+l/JfCZwxwrSZpnXQbEOPBw3/KeZt0sSU4AVgF/exhjVyeZSjI1MzPzgouWJPV0GRBpWVdz9H0n8NWqeuxQx1bVxqqarKrJpUuXHkaZkqQ2XQbEHuCsvuVlwL45+l7BTw8vHepYSVIHugyIrcCKJOckOZ5eCGwe7JTkVOCXgc8d6lhJUneO62rDVbU/yTXArcAYcENV7UpyddO+oel6OXBbVT15sLFd1SpJmq2zgACoqi3AloF1GwaWbwRuHGasJOnI8UpqSVIrA0KS1MqAkCS1MiAkSa0MCElSq05/xXQ02bt3L2NP/YAl9/vDKf3U2FPfY+/e/aMuQxoJ9yAkSa3cg2iMj4/zf358HE+f+45Rl6IFZMn9WxgfP3PUZUgj4R6EJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWnUaEElWJXkgyXSSa+fo85Yk25PsSvKVvvUPJtnRtE11WackabbOLpRLMgZcD1xC7x7TW5Nsrqp7+/qcBnwCWFVVDyU5Y2AzF1fVo13VKEmaW5d7ECuB6araXVXPADcDlw30eQ/w2ap6CKCqHumwHknSIegyIMaBh/uW9zTr+v0C8NIkX06yLcl7+9oKuK1Zv3quN0myOslUkqmZmZl5K16SFrsu52JKy7pqef83AG8FlgBfS/L1qvomcFFV7WsOO92e5P6qumPWBqs2AhsBJicnB7cvSTpMXe5B7AHO6lteBuxr6XNLVT3ZnGu4AzgfoKr2Nc+PAJvoHbKSJB0hXQbEVmBFknOSHA9cAWwe6PM54E1JjktyAnAhcF+SE5OcDJDkROBSYGeHtUqSBnR2iKmq9ie5BrgVGANuqKpdSa5u2jdU1X1JbgHuAZ4DPl1VO5O8EtiU5ECNN1XVLV3VKkmardP7QVTVFmDLwLoNA8vXAdcNrNtNc6hJkjQa3jCoz9hTj3nLUeBFP/ohAM+95JQRVzJ6Y089BnjDIC1OBkRjYmJi1CUsGNPTjwMw8Ur/Y4Qz/Wxo0TIgGmvWrBl1CQvG2rVrAVi3bt2IK5E0Sk7WJ0lqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlq1WlAJFmV5IEk00munaPPW5JsT7IryVcOZawkqTudTfedZAy4HrgE2ANsTbK5qu7t63Ma8AlgVVU9lOSMYcdKkrrV5R7ESmC6qnZX1TPAzcBlA33eA3y2qh4CqKpHDmGsJKlDXQbEOPBw3/KeZl2/XwBemuTLSbYlee8hjAUgyeokU0mmZmZm5ql0SVKXd5RLy7pqef83AG8FlgBfS/L1Icf2VlZtBDYCTE5OtvaRJB26LgNiD3BW3/IyYF9Ln0er6kngySR3AOcPOVaS1KEuDzFtBVYkOSfJ8cAVwOaBPp8D3pTkuCQnABcC9w05VpLUoc72IKpqf5JrgFuBMeCGqtqV5OqmfUNV3ZfkFuAe4Dng01W1E6BtbFe1SpJm6/IQE1W1BdgysG7DwPJ1wHXDjJUkHTleSS1JamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlq1emV1Dp069evZ3p6eqQ1HHj/tWvXjrQOgImJCdasWTPqMqRFyYDQLEuWLBl1CZIWAANigfHbsqSFwnMQkqRWBoQkqZUBIUlqZUBIklp1GhBJViV5IMl0kmtb2t+S5AdJtjeP/9TX9mCSHc36qS7rlCTN1tmvmJKMAdcDlwB7gK1JNlfVvQNd/7Gq/tUcm7m4qh7tqkZJ0ty63INYCUxX1e6qega4Gbisw/eTJM2jLgNiHHi4b3lPs27QG5PcneQLSV7Tt76A25JsS7J6rjdJsjrJVJKpmZmZ+alcktTphXJpWVcDy3cCr6iqJ5K8A/g7YEXTdlFV7UtyBnB7kvur6o5ZG6zaCGwESDKT5Nvz9hcsbqcDHt7TQuXnc/68Yq6GLgNiD3BW3/IyYF9/h6r6Yd/rLUk+keT0qnq0qvY16x9JsoneIatZATGwvaXzVv0il2SqqiZHXYfUxs/nkdHlIaatwIok5yQ5HrgC2NzfIcnPJ0nzemVTz/eSnJjk5Gb9icClwM4Oa5UkDehsD6Kq9ie5BrgVGANuqKpdSa5u2jcA7wJ+O8l+4GngiqqqJGcCm5rsOA64qapu6apWSdJsqRo8LSD1Tv4353ekBcfP55FhQEiSWjnVhiSplQEhSWplQCxCSU5L8u8Oc+wHk5ww3zVp8UryRPP88iR/M0efLyd53p+1Dn42k2xJctq8FrvIGBCL02nAYQUE8EHAgNC8q6p9VfWuF7CJD9L32ayqd1TV/32hdS1mBsTi9DHgnzQz5V6X5ENJtia5J8kfQu/6kyT/s5kGZWeSdyf5HeDlwJeSfGmkf4EWrCR/0r+HmuQPkvznJF9McmczS/OsedmSLE+ys3m9JMnNzWfyfwBL+vp9spleZ1ff53XWZ7OZEfr05vXvNp/jnUk+2Pd+9yX5s2ZbtyXxhuz9qsrHInsAy4GdzetL6U1VEnpfGP4eeDPwa8Cf9Y05tXl+EDh91H+Dj4X7AP4Z8JW+5XuBs4FTmuXTgWl++ivKJ5rn/s/l79K7dgrgdcB+YLJZflnzPAZ8GXhds/wzn80Dy8AbgB3AicBJwK6mxuXNdi9o+v818Buj/vdbSA/3IHRp87iL3txY59KbD2sH8C+bb4NvqqofjLBGHUWq6i7gjOacwvnA94HvAB9Ncg/wD/Qm7jzzeTbzZuAvm+3dA9zT1/ZvktxJ7zP7GuC8g5T0L4BNVfVkVT0BfBZ4U9P2rara3rzeRi801OhyLiYdHQL8cVV9alZD8gbgHcAfJ7mtqv7oiFeno9Xf0Jsp4efpTfX/68BS4A1V9ZMkDwIvOcg2Zl2kleQc4PeAX6yq7ye5cYjttE0cesCP+14/S9+hLHkOYrF6HDi5eX0r8L4kJwEkGU9yRpKXA09V1V8Cfwq8vmWsNJeb6c2/9i56YXEq8EgTDhfzPDOINu6gFyokeS29w0wApwBPAj9opuR5e9+YuT6bdwD/OskJzdxulwP/eFh/1SLjHsQiVFXfS/LV5oTgF4CbgK81c189AfwGMAFcl+Q54CfAbzfDNwJfSPKdqrr4yFevo0H15l07GdhbVd9J8lfA55vbB28H7j/IJj4J/HlzSGo78I1mu3cnuYveeYTdwFf7xrR+NqvqzmZP4xvNqk9X1V1Jlr/AP/OY51QbkqRWHmKSJLUyICRJrQwISVIrA0KS1MqAkCS1MiCkEUjym821JtKCZUBIo/Gb9CaXkxYsr4OQ5klzle5fA8voTST3EXqT0v1XepPEPUovGC4CbgT2Ak8Db6yqp498xdLzMyCkeZLk14BVVfVvm+VT6V2pfllVzSR5N/C2qnpfki8Dv1dVU6OrWHp+TrUhzZ8dwJ8m+RN606Z/H3gtcHszjckYvVlNpaOCASHNk6r6Zv8MuMDtwK6qeuNoK5MOjyeppXnSMgPuhcDSJG9s2n8uyWua7s6KqwXPPQhp/vxTZs+Aux/47835iOOA/0ZvJtIbgQ1JPEmtBcuT1JKkVh5ikiS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUqv/B+WYGOVDeIT6AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "results = []\n",
        "best_n_neighbors = []\n",
        "X_train_sig_a = X_train_sig.to_numpy()\n",
        "y_train_a = y_train.to_numpy()\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_sig_a,y_train_a):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_sig_a[validation_index]\n",
        "    y_validation = y_train_a[validation_index]\n",
        "    \n",
        "    X_test = X_train_sig_a[test_index]\n",
        "    y_test = y_train_a[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_estimators\": list(range(1, 50))}\n",
        "    rf = RandomForestClassifier(criterion= \"gini\", bootstrap = True, min_samples_leaf = 5)\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "    grid_search = model_selection.GridSearchCV(rf, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: n={clf.n_estimators}')\n",
        "    best_n_neighbors.append(clf.n_estimators)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_test)\n",
        "    scores = probabilities[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_test, scores)\n",
        "    results.append({\n",
        "        'auc': auc,\n",
        "        'n': clf.n_estimators,\n",
        "        'set': 'test'\n",
        "    })\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'n': clf.n_estimators,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "H&N group 12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
