{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPGqFph0hWNA"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1137,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# # Run this to use from colab environment\n",
        "# !pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "e1614342-6bac-4c4b-d431-f01272b75dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n",
            "               hf_energy  hf_entropy  hf_kurtosis    hf_max   hf_mean  \\\n",
            "ID                                                                      \n",
            "0_HN1006_0  24345.357124    3.444203    30.940366  2.677051  2.548128   \n",
            "0_HN1022_0  35301.370880    2.873434    26.545182  2.382068  2.155280   \n",
            "0_HN1026_0   6340.950214    2.769541    36.348167  2.690379  2.280517   \n",
            "0_HN1029_0   5690.500179    3.073200    22.336711  2.396042  1.985643   \n",
            "0_HN1046_0  15553.548185    3.025631    17.749920  2.496800  2.197910   \n",
            "...                  ...         ...          ...       ...       ...   \n",
            "0_HN1950_0  50004.678306    2.246432   126.285018  2.525254  2.398012   \n",
            "0_HN1954_0  58235.863884    2.554536    76.204185  2.820189  2.629647   \n",
            "0_HN1968_0  16630.150022    2.341213    32.813802  2.822103  2.290915   \n",
            "0_HN1987_0  58087.164347    2.159815    54.656463  2.111198  1.981591   \n",
            "0_HN1998_0  12724.205929    3.085224    17.632549  2.444499  2.256216   \n",
            "\n",
            "            hf_median    hf_min  hf_peak  hf_quartile_range  hf_range  ...  \\\n",
            "ID                                                                     ...   \n",
            "0_HN1006_0   2.558302  2.385205      294           0.055232  0.291846  ...   \n",
            "0_HN1022_0   2.258897  0.662800     4862           0.130870  1.719268  ...   \n",
            "0_HN1026_0   2.294630  1.672403      446           0.101971  1.017976  ...   \n",
            "0_HN1029_0   2.053187  0.449525      891           0.103764  1.946517  ...   \n",
            "0_HN1046_0   2.313436  0.257690     1819           0.113634  2.239110  ...   \n",
            "...               ...       ...      ...                ...       ...  ...   \n",
            "0_HN1950_0   2.398771  2.280280     1998           0.061270  0.244974  ...   \n",
            "0_HN1954_0   2.655308  2.250091     3290           0.125757  0.570099  ...   \n",
            "0_HN1968_0   2.290181  2.002533     1976           0.081458  0.819570  ...   \n",
            "0_HN1987_0   2.024973  1.308831    12111           0.059878  0.802367  ...   \n",
            "0_HN1998_0   2.361756  1.070060     1045           0.125038  1.374439  ...   \n",
            "\n",
            "            tf_LBP_skew_R3_P12  tf_LBP_skew_R8_P24  tf_LBP_std_R15_P36  \\\n",
            "ID                                                                       \n",
            "0_HN1006_0           -0.013623           -0.740877           11.184061   \n",
            "0_HN1022_0           -0.449861           -1.600916           11.806938   \n",
            "0_HN1026_0           -0.400584           -2.044795           10.398354   \n",
            "0_HN1029_0           -0.215486           -1.361815           10.210308   \n",
            "0_HN1046_0           -0.018494           -1.272544           11.997325   \n",
            "...                        ...                 ...                 ...   \n",
            "0_HN1950_0           -0.441309           -1.808393            6.658848   \n",
            "0_HN1954_0           -0.261114           -1.252389           13.095591   \n",
            "0_HN1968_0           -0.356150           -1.386744           12.433966   \n",
            "0_HN1987_0           -0.614919           -1.829959           11.270492   \n",
            "0_HN1998_0            0.176036           -0.731095            9.473624   \n",
            "\n",
            "            tf_LBP_std_R3_P12  tf_LBP_std_R8_P24  tf_NGTDM_Busyness  \\\n",
            "ID                                                                    \n",
            "0_HN1006_0           5.280484          11.146737           0.000000   \n",
            "0_HN1022_0           5.127799           8.971347          12.490025   \n",
            "0_HN1026_0           5.075791           7.978472           0.243968   \n",
            "0_HN1029_0           5.162952           9.888348           3.785102   \n",
            "0_HN1046_0           4.619492           9.292694           7.858607   \n",
            "...                       ...                ...                ...   \n",
            "0_HN1950_0           5.182012           8.714246           0.000000   \n",
            "0_HN1954_0           4.895519           9.613529           1.614541   \n",
            "0_HN1968_0           5.269350           9.681940           0.101255   \n",
            "0_HN1987_0           5.138261           8.522201          17.680150   \n",
            "0_HN1998_0           4.663843          10.794366           1.006037   \n",
            "\n",
            "            tf_NGTDM_Coarseness  tf_NGTDM_Complexity  tf_NGTDM_Contrast  \\\n",
            "ID                                                                        \n",
            "0_HN1006_0       1000000.000000             0.000000       0.000000e+00   \n",
            "0_HN1022_0             0.020387             0.008373       1.090935e-04   \n",
            "0_HN1026_0             1.027099             0.001501       3.528037e-06   \n",
            "0_HN1029_0             0.067553             0.012214       1.917977e-04   \n",
            "0_HN1046_0             0.032584             0.012581       2.093031e-04   \n",
            "...                         ...                  ...                ...   \n",
            "0_HN1950_0       1000000.000000             0.000000       0.000000e+00   \n",
            "0_HN1954_0             0.155069             0.001257       1.381761e-06   \n",
            "0_HN1968_0             2.469993             0.000216       9.970363e-08   \n",
            "0_HN1987_0             0.014336             0.005322       5.282298e-05   \n",
            "0_HN1998_0             0.249240             0.002649       6.309797e-06   \n",
            "\n",
            "            tf_NGTDM_Strength  \n",
            "ID                             \n",
            "0_HN1006_0           0.000000  \n",
            "0_HN1022_0           0.018735  \n",
            "0_HN1026_0           0.672940  \n",
            "0_HN1029_0           0.062940  \n",
            "0_HN1046_0           0.030421  \n",
            "...                       ...  \n",
            "0_HN1950_0           0.000000  \n",
            "0_HN1954_0           0.137259  \n",
            "0_HN1968_0           1.423791  \n",
            "0_HN1987_0           0.013049  \n",
            "0_HN1998_0           0.206874  \n",
            "\n",
            "[113 rows x 159 columns]\n"
          ]
        }
      ],
      "source": [
        "from load_data import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import seaborn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats import weightstats\n",
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "# Classifiers and kernels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "features = data.drop(columns=['label'])\n",
        "label = data.label\n",
        "\n",
        "# Splitting data in train and test group\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=.2)\n",
        "print(features)\n",
        "# functie van maken??\n",
        "y_train_bin = []\n",
        "for val in y_train:\n",
        "  if val == 'T12':\n",
        "    y_train_bin.append(0)\n",
        "  else:\n",
        "    y_train_bin.append(1) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8qaMN_7Unb"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAa7WJCd56fk"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1139,
      "metadata": {
        "id": "q6BJaMI37Vq7"
      },
      "outputs": [],
      "source": [
        "# Scale the dataset\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns = features.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns = features.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1140,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the dataframe\n",
        "outlier_feat = []\n",
        "for feature in X_train_scaled.columns:\n",
        "    # IQR\n",
        "    Q1 = np.percentile(X_train_scaled[feature], 25,\n",
        "                    interpolation = 'midpoint')\n",
        "    \n",
        "    Q3 = np.percentile(X_train_scaled[feature], 75,\n",
        "                    interpolation = 'midpoint')\n",
        "    IQR = Q3 - Q1\n",
        " \n",
        "    # Upper bound\n",
        "    #np.where(features[feature] >= (Q3+1.5*IQR),features[feature],100000000000000000)\n",
        "    X_train_scaled.loc[X_train_scaled[feature] >= (Q3+1.5*IQR),feature] = statistics.median(X_train_scaled[feature])\n",
        "    # features[feature].iloc([0,list(upper)]) = statistics.median(features[feature])\n",
        "    # Lower bound\n",
        "    # np.where(features[feature] <= (Q1-1.5*IQR),features[feature],100000000000000000)\n",
        "    X_train_scaled.loc[X_train_scaled[feature] <= (Q3-1.5*IQR),feature] = statistics.median(X_train_scaled[feature])\n",
        "\n",
        "\n",
        "for feature in X_test_scaled.columns:\n",
        "    # IQR\n",
        "    Q1 = np.percentile(X_test_scaled[feature], 25,\n",
        "                    interpolation = 'midpoint')\n",
        "    \n",
        "    Q3 = np.percentile(X_test_scaled[feature], 75,\n",
        "                    interpolation = 'midpoint')\n",
        "    IQR = Q3 - Q1\n",
        " \n",
        "    # Upper bound\n",
        "    #np.where(features[feature] >= (Q3+1.5*IQR),features[feature],100000000000000000)\n",
        "    X_test_scaled.loc[X_test_scaled[feature] >= (Q3+1.5*IQR),feature] = statistics.median(X_test_scaled[feature])\n",
        "    # features[feature].iloc([0,list(upper)]) = statistics.median(features[feature])\n",
        "    # Lower bound\n",
        "    # np.where(features[feature] <= (Q1-1.5*IQR),features[feature],100000000000000000)\n",
        "    X_test_scaled.loc[X_test_scaled[feature] <= (Q3-1.5*IQR),feature] = statistics.median(X_test_scaled[feature])\n",
        "\n",
        "# Splitting data in train and test group\n",
        "# X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=.2)\n",
        "\n",
        "# functie van maken??\n",
        "y_train_bin = []\n",
        "for val in y_train:\n",
        "  if val == 'T12':\n",
        "    y_train_bin.append(0)\n",
        "  else:\n",
        "    y_train_bin.append(1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### removing outliers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V55PGYOyPp0A"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQsEWuviPvxG"
      },
      "source": [
        "### T-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PXDFa7mVPyd2",
        "outputId": "aca9c33a-f77f-4dab-b235-413a806be361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of significant different features: 25\n"
          ]
        }
      ],
      "source": [
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns = X_train.columns) # make df from numpy\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_train.columns)\n",
        "X_train_scaled_df['Label'] = y_train_bin\n",
        "X_train_T12 = X_train_scaled_df.groupby('Label').get_group(0)\n",
        "X_train_T34 = X_train_scaled_df.groupby('Label').get_group(1)\n",
        "X_train_T12 = X_train_T12.drop(columns = ['Label'])\n",
        "X_train_T34 = X_train_T34.drop(columns = ['Label'])\n",
        "\n",
        "# ttest\n",
        "_,pval = stats.ttest_ind(X_train_T12,X_train_T34)\n",
        "\n",
        "\n",
        "\n",
        "sig_feat = []\n",
        "for id, val in enumerate(pval):\n",
        "  if val < 0.05/X_train_scaled_df.shape[1]:\n",
        "    sig_feat.append(list(X_train.columns)[id])\n",
        "print(f'Number of significant different features: {len(sig_feat)}')\n",
        "\n",
        "X_train_sig = X_train_scaled_df[sig_feat]\n",
        "X_test_sig = X_test_scaled_df[sig_feat]\n",
        "# #Pairplot of sign features\n",
        "# X_train_sig.columns =['Feature'+ str(pc) for pc in range(1,len(sig_feat)+1)]\n",
        "# X_train_sig['Label'] = y_train_bin\n",
        "# pair_plot = seaborn.pairplot(X_train_sig, hue = 'Label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emhz-AV_yGv"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1142,
      "metadata": {
        "id": "qR_LfjKs-V9s"
      },
      "outputs": [],
      "source": [
        "# N_COMP = 10\n",
        "# pca = PCA(n_components=N_COMP)\n",
        "# pca.fit(X_train_sig)\n",
        "# X_train_pca = pca.transform(X_train_sig)\n",
        "# X_test_pca = pca.transform(X_test_sig)\n",
        "\n",
        "\n",
        "# seaborn.scatterplot(x=X_train_pca[:,0],y=X_train_pca[:,1],hue=y_train)\n",
        "# scatter_data = pd.DataFrame(X_train_pca[:,:], columns = ['Principal component' + str(pc) for pc in range(1,N_COMP+1)])\n",
        "# scatter_data['Stage'] = y_train_bin\n",
        "# seaborn.pairplot(scatter_data, hue = 'Stage')\n",
        "# print(scatter_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQWNGavlBlF0"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing variety of classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ztLj3EAJyU",
        "outputId": "ca47719e-ce58-4b90-d5dd-61fb8abcf6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier()\n",
            "Train data acc: 0.8222222222222222\n",
            "Test data acc: 0.5217391304347826\n",
            "RandomForestClassifier()\n",
            "Train data acc: 1.0\n",
            "Test data acc: 0.6521739130434783\n",
            "QuadraticDiscriminantAnalysis()\n",
            "Train data acc: 0.8777777777777778\n",
            "Test data acc: 0.6086956521739131\n",
            "GaussianNB()\n",
            "Train data acc: 0.7555555555555555\n",
            "Test data acc: 0.6956521739130435\n",
            "LinearDiscriminantAnalysis()\n",
            "Train data acc: 0.8444444444444444\n",
            "Test data acc: 0.6956521739130435\n",
            "SVC(kernel='linear')\n",
            "Train data acc: 0.8222222222222222\n",
            "Test data acc: 0.782608695652174\n",
            "SVC(kernel='poly')\n",
            "Train data acc: 0.7888888888888889\n",
            "Test data acc: 0.6956521739130435\n",
            "SVC()\n",
            "Train data acc: 0.8111111111111111\n",
            "Test data acc: 0.6956521739130435\n"
          ]
        }
      ],
      "source": [
        "# Construct classifiers\n",
        "svmlin = SVC(kernel='linear', gamma='scale')\n",
        "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
        "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
        "\n",
        "clsfs = [KNeighborsClassifier(), RandomForestClassifier(),QuadraticDiscriminantAnalysis(),GaussianNB(),LinearDiscriminantAnalysis(),svmlin, svmpoly, svmrbf]\n",
        "\n",
        "for clf in clsfs:\n",
        "    # Fit classifier\n",
        "    clf.fit(X_train_sig,y_train)\n",
        "    y_pred_train=clf.predict(X_train_sig)\n",
        "    print(clf)\n",
        "    acc_train = (y_train==y_pred_train).sum()/len(X_train_sig)\n",
        "    print(f'Train data acc: {acc_train}')\n",
        "    y_pred_test = clf.predict(X_test_sig)\n",
        "    acc_test = (y_test==y_pred_test).sum()/len(X_test_sig)\n",
        "    print(f'Test data acc: {acc_test}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1144,
      "metadata": {
        "id": "TnfuoX7LB8D7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best classifier: k=9\n",
            "Best classifier: k=9\n",
            "Best classifier: k=9\n",
            "Best classifier: k=9\n",
            "Best classifier: k=9\n",
            "The optimal N=9\n",
            "THe AUC on the replication set is 0.7992424242424243 using a 9-NN classifier\n",
            "Training result kNN: 0.7777777777777778\n",
            "Test result kNN: 0.6521739130434783\n"
          ]
        }
      ],
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "results = []\n",
        "best_n_neighbors = []\n",
        "X_train_sig_a = X_train_sig.to_numpy()\n",
        "y_train_a = y_train.to_numpy()\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_sig_a,y_train_a):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_sig_a[validation_index]\n",
        "    y_validation = y_train_a[validation_index]\n",
        "    \n",
        "    X_test_op = X_train_sig_a[test_index]\n",
        "    y_test_op = y_train_a[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_neighbors\": list(range(1, 11, 2))}\n",
        "    knn = KNeighborsClassifier()\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "    grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_neighbors}')\n",
        "    best_n_neighbors.append(clf.n_neighbors)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_test_op)\n",
        "    scores = probabilities[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_test_op, scores)\n",
        "    results.append({\n",
        "        'auc': auc,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'test'\n",
        "    })\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "# seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "# print(results)\n",
        "\n",
        "\n",
        "# Use the optimal parameters without any tuning to validate the optimal classifier\n",
        "clf = KNeighborsClassifier(n_neighbors=optimal_n)\n",
        "\n",
        "# Fit on the entire dataset\n",
        "clf.fit(X_train_sig, y_train)\n",
        "\n",
        "# Test the classifier on the indepedent replication data\n",
        "probabilities = clf.predict_proba(X_test_sig)\n",
        "scores = probabilities[:, 1]\n",
        "\n",
        "# Get the auc\n",
        "auc = metrics.roc_auc_score(y_test, scores)\n",
        "print(f'THe AUC on the replication set is {auc} using a {clf.n_neighbors}-NN classifier')\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=optimal_n)\n",
        "knn.fit(X_train_sig, y_train)\n",
        "score_train_kNN = knn.score(X_train_sig, y_train)\n",
        "score_test_kNN = knn.score(X_test_sig, y_test)\n",
        "print(f\"Training result kNN: {score_train_kNN}\")\n",
        "print(f\"Test result kNN: {score_test_kNN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1045,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23,)\n",
            "(23, 16)\n"
          ]
        }
      ],
      "source": [
        "print(y_test.shape)\n",
        "print(X_test_sig.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1027,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best classifier: k=45\n",
            "Best classifier: k=30\n",
            "Best classifier: k=5\n",
            "Best classifier: k=21\n",
            "Best classifier: k=45\n",
            "The optimal N=30\n",
            "        auc   n         set\n",
            "0  0.827160  45        test\n",
            "1  0.958333  45  validation\n",
            "2  0.777778  30        test\n",
            "3  0.956019  30  validation\n",
            "4  0.888889   5        test\n",
            "5  0.933642   5  validation\n",
            "6  0.666667  21        test\n",
            "7  0.962191  21  validation\n",
            "8  0.839506  45        test\n",
            "9  0.959877  45  validation\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "results = []\n",
        "best_n_neighbors = []\n",
        "X_train_sig_a = X_train_sig.to_numpy()\n",
        "y_train_a = y_train.to_numpy()\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_sig_a,y_train_a):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_sig_a[validation_index]\n",
        "    y_validation = y_train_a[validation_index]\n",
        "    \n",
        "    X_test = X_train_sig_a[test_index]\n",
        "    y_test = y_train_a[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_estimators\": list(range(1, 50))}\n",
        "    rf = RandomForestClassifier(criterion= \"gini\", bootstrap = True, min_samples_leaf = 5)\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=5)\n",
        "    grid_search = model_selection.GridSearchCV(rf, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: n={clf.n_estimators}')\n",
        "    best_n_neighbors.append(clf.n_estimators)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_test)\n",
        "    scores = probabilities[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_test, scores)\n",
        "    results.append({\n",
        "        'auc': auc,\n",
        "        'n': clf.n_estimators,\n",
        "        'set': 'test'\n",
        "    })\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'n': clf.n_estimators,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "H&N group 12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
