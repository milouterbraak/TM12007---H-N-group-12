{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPGqFph0hWNA"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# # Run this to use from colab environment\n",
        "# !pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "e1614342-6bac-4c4b-d431-f01272b75dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n"
          ]
        }
      ],
      "source": [
        "from load_data import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import seaborn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats import weightstats\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "features = data.drop(columns=['label'])\n",
        "label = data.label\n",
        "\n",
        "# Splitting data in train and test group\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=.2)\n",
        "\n",
        "# functie van maken??\n",
        "y_train_bin = []\n",
        "for val in y_train:\n",
        "  if val == 'T12':\n",
        "    y_train_bin.append(0)\n",
        "  else:\n",
        "    y_train_bin.append(1) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAa7WJCd56fk"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8qaMN_7Unb"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q6BJaMI37Vq7"
      },
      "outputs": [],
      "source": [
        "# Scale the dataset\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V55PGYOyPp0A"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQsEWuviPvxG"
      },
      "source": [
        "### T-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PXDFa7mVPyd2",
        "outputId": "aca9c33a-f77f-4dab-b235-413a806be361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of significant different features: 18\n"
          ]
        }
      ],
      "source": [
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns = X_train.columns) # make df from numpy\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_train.columns)\n",
        "X_train_scaled_df['Label'] = y_train_bin\n",
        "X_train_T12 = X_train_scaled_df.groupby('Label').get_group(0)\n",
        "X_train_T34 = X_train_scaled_df.groupby('Label').get_group(1)\n",
        "X_train_T12 = X_train_T12.drop(columns = ['Label'])\n",
        "X_train_T34 = X_train_T34.drop(columns = ['Label'])\n",
        "\n",
        "# ttest\n",
        "_,pval = stats.ttest_ind(X_train_T12,X_train_T34)\n",
        "\n",
        "\n",
        "\n",
        "sig_feat = []\n",
        "for id, val in enumerate(pval):\n",
        "  if val < 0.05/X_train_scaled_df.shape[1]:\n",
        "    sig_feat.append(list(X_train.columns)[id])\n",
        "print(f'Number of significant different features: {len(sig_feat)}')\n",
        "\n",
        "X_train_sig = X_train_scaled_df[sig_feat]\n",
        "X_test_sig = X_test_scaled_df[sig_feat]\n",
        "\n",
        "# # Pairplot of sign features\n",
        "# X_train_sig.columns =['Feature'+ str(pc) for pc in range(1,len(sig_feat)+1)]\n",
        "# X_train_sig['Grade'] = y_train_bin\n",
        "# pair_plot = seaborn.pairplot(X_train_sig, hue = 'Grade')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emhz-AV_yGv"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qR_LfjKs-V9s"
      },
      "outputs": [],
      "source": [
        "N_COMP = 10\n",
        "pca = PCA(n_components=N_COMP)\n",
        "pca.fit(X_train_sig)\n",
        "X_train_pca = pca.transform(X_train_sig)\n",
        "X_test_pca = pca.transform(X_test_sig)\n",
        "\n",
        "\n",
        "# seaborn.scatterplot(x=X_train_pca[:,0],y=X_train_pca[:,1],hue=y_train)\n",
        "# scatter_data = pd.DataFrame(X_train_pca[:,:], columns = ['Principal component' + str(pc) for pc in range(1,N_COMP+1)])\n",
        "# scatter_data['Stage'] = y_train_bin\n",
        "# seaborn.pairplot(scatter_data, hue = 'Stage')\n",
        "# print(scatter_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQWNGavlBlF0"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ztLj3EAJyU",
        "outputId": "ca47719e-ce58-4b90-d5dd-61fb8abcf6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training result kNN: 0.7333333333333333\n",
            "Test result kNN: 0.7391304347826086\n",
            "Training result Random Forest: 0.9777777777777777\n",
            "Test result Random Forest: 0.7391304347826086\n"
          ]
        }
      ],
      "source": [
        "# kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train_pca, y_train)\n",
        "score_train_kNN = knn.score(X_train_pca, y_train)\n",
        "score_test_kNN = knn.score(X_test_pca, y_test)\n",
        "print(f\"Training result kNN: {score_train_kNN}\")\n",
        "print(f\"Test result kNN: {score_test_kNN}\")\n",
        "\n",
        "\n",
        "# RF with PCA\n",
        "# clf = RandomForestClassifier(n_estimators=5, bootstrap=True)\n",
        "# clf.fit(X_train_pca, y_train)\n",
        "# score_train_RF = clf.score(X_train_pca, y_train)\n",
        "# score_test_RF = clf.score(X_test_pca, y_test)\n",
        "# print(f\"Training result Random Forest: {score_train_RF}\")\n",
        "# print(f\"Test result Random Forest: {score_test_RF}\")\n",
        "\n",
        "\n",
        "# RF without PCA\n",
        "clf = RandomForestClassifier(n_estimators=5, bootstrap=True)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "score_train_RF = clf.score(X_train_scaled, y_train)\n",
        "score_test_RF = clf.score(X_test_scaled, y_test)\n",
        "print(f\"Training result Random Forest: {score_train_RF}\")\n",
        "print(f\"Test result Random Forest: {score_test_RF}\")\n",
        "\n",
        "# Print result\n",
        "\n",
        "# print(f\"Test result: {score_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnfuoX7LB8D7"
      },
      "outputs": [],
      "source": [
        "-"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "H&N group 12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
